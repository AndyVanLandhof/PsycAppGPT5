/**
 * Evaluate synthetic Edexcel 9ET0/03 Poetry questions against real style.
 *
 * Usage:
 *   node scripts/run-question-eval-englit.cjs
 *
 * Inputs:
 *   - public/exam-eval/edexcel-9et0-p3_synthetic-questions.json
 *   - June 2019 QP - Paper 3 Edexcel English Literature A-level_extracted.txt
 *
 * Output:
 *   - public/exam-eval/edexcel-9et0-p3_question-report.json
 */

require('dotenv').config();
const fs = require('fs');
const path = require('path');

const ANTHROPIC_API_KEY = process.env.ANTHROPIC_API_KEY;
const ANTHROPIC_MODEL = process.env.ANTHROPIC_MODEL || 'claude-3-7-sonnet-20250219';

if (!ANTHROPIC_API_KEY) {
  console.error('‚ùå ANTHROPIC_API_KEY is not set in .env ‚Äì cannot run Edexcel question eval.');
  process.exit(1);
}

const ROOT = path.join(__dirname, '..');
const SYNTH_FILE = path.join(ROOT, 'public', 'exam-eval', 'edexcel-9et0-p3_synthetic-questions.json');
const QP_PATH = path.join(
  ROOT,
  'public',
  'vault',
  'ocr-rs',
  'vault',
  'PastPapers',
  'English Literature',
  'June 2019 QP - Paper 3 Edexcel English Literature A-level_extracted.txt'
);
const REPORT_FILE = path.join(ROOT, 'public', 'exam-eval', 'edexcel-9et0-p3_question-report.json');

function readJson(file) {
  return JSON.parse(fs.readFileSync(file, 'utf8'));
}

function readText(file) {
  return fs.readFileSync(file, 'utf8');
}

function extractPoetryQuestionStems(text, maxChars = 9000) {
  const lines = text.split('\n');
  const stems = [];
  let current = null;
  let buffer = [];

  for (let i = 0; i < lines.length; i++) {
    const raw = lines[i];
    const line = raw.trim();
    const qMatch = line.match(/^Question\s+(\d+)\s*(.+)?$/i);
    if (qMatch) {
      if (current && buffer.length > 0) {
        current.text = buffer.join(' ');
        stems.push(`Question ${current.number}: ${current.text}`);
        buffer = [];
      }
      current = {
        number: qMatch[1],
        text: qMatch[2] || ''
      };
      continue;
    }

    const marksMatch = line.match(/\(Total for Question \d+ = (\d+)\s*marks\)/i);
    if (marksMatch && current) {
      continue;
    }

    if (current && line) {
      buffer.push(line);
    }
  }

  if (current && buffer.length > 0) {
    current.text = buffer.join(' ');
    stems.push(`Question ${current.number}: ${current.text}`);
  }

  let buf = stems.join('\n\n');
  if (buf.length > maxChars) {
    buf = buf.slice(0, maxChars);
  }
  return buf;
}

async function callAnthropic(prompt) {
  const res = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': ANTHROPIC_API_KEY,
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: ANTHROPIC_MODEL,
      max_tokens: 900,
      temperature: 0.2,
      messages: [
        {
          role: 'user',
          content: prompt
        }
      ]
    })
  });

  if (!res.ok) {
    const body = await res.text();
    throw new Error(`Anthropic error ${res.status}: ${body}`);
  }

  const data = await res.json();
  const text = (data.content && data.content[0] && data.content[0].text) || '';
  try {
    return JSON.parse(text);
  } catch {
    const match = text.match(/\{[\s\S]*\}/);
    if (match) return JSON.parse(match[0]);
    throw new Error(`Failed to parse JSON from Anthropic response: ${text.slice(0, 200)}...`);
  }
}

function buildEvalPrompt(realStems, q) {
  return `
You are a senior Edexcel A-level English Literature question-setting specialist for:
  Specification: 9ET0
  Paper 3: Poetry (9ET0/03).

You will be shown:
- REAL past-paper question stems from 9ET0/03 (for style reference).
- ONE SYNTHETIC QUESTION generated by an AI.

Your job is to judge whether the SYNTHETIC QUESTION is:
- On-spec for 9ET0/03 Poetry.
- Stylistically consistent with real Paper 3 questions.
- Appropriately weighted in marks and command word.
- Roughly in the right difficulty band (too easy | typical | too hard).

REAL EDEXCEL QUESTION STEMS (for style reference ‚Äì do NOT copy):
${realStems}

NOW EVALUATE THIS SYNTHETIC QUESTION:

ID: ${q.id}
Topic area: ${q.topicArea || '(unspecified)'}
Sub-area: ${q.subArea || '(unspecified)'}
Command word: ${q.commandWord || '(unspecified)'}
Marks: ${q.marks}

TEXT:
${q.text}

Using your knowledge of Edexcel 9ET0/03 and the examples above, answer in STRICT JSON:
{
  "onSpec": true,
  "specTopicGuess": "Short description of likely spec area(s) and texts this targets",
  "commandWordOk": true,
  "marksAppropriate": true,
  "styleMatchScore": 0.0,
  "difficultyBand": "too easy | typical | too hard",
  "tooSimilarToReal": false,
  "closestRealQuestionStyle": "Very short description comparing to one of the real stems above",
  "issues": [
    "Any problems (off-spec, uses non-set texts, trivial, badly worded, almost duplicate of real question, etc.)"
  ],
  "overallComment": "2‚Äì3 sentence plain-English verdict on whether this would be acceptable as a real Edexcel 9ET0/03 Paper 3 question."
}
`;
}

async function main() {
  console.log('üîé Evaluating synthetic Edexcel 9ET0/03 Poetry questions...');
  console.log('  Synthetic file :', SYNTH_FILE);
  console.log('  Real QP        :', QP_PATH);

  const synth = readJson(SYNTH_FILE);
  const qpText = readText(QP_PATH);
  const realStems = extractPoetryQuestionStems(qpText);

  const questions = synth.questions || [];
  if (!questions.length) {
    console.error('‚ùå No questions found in synthetic file.');
    process.exit(1);
  }

  const results = [];

  for (const q of questions) {
    console.log(`\nüß™ Evaluating synthetic question ${q.id || '(no id)'}...`);
    const prompt = buildEvalPrompt(realStems, q);
    try {
      const evalJson = await callAnthropic(prompt);
      results.push({
        id: q.id,
        topicArea: q.topicArea,
        subArea: q.subArea,
        commandWord: q.commandWord,
        marks: q.marks,
        text: q.text,
        eval: evalJson
      });
      console.log(
        `   -> onSpec: ${evalJson.onSpec}, styleMatch: ${evalJson.styleMatchScore}, difficulty: ${evalJson.difficultyBand}`
      );
    } catch (e) {
      console.error('   ‚ùå Error evaluating question:', e.message);
      results.push({
        id: q.id,
        topicArea: q.topicArea,
        subArea: q.subArea,
        commandWord: q.commandWord,
        marks: q.marks,
        text: q.text,
        error: e.message
      });
    }
  }

  const summary = {
    spec: synth.spec || 'Edexcel 9ET0/03 Poetry',
    model: ANTHROPIC_MODEL,
    totalQuestions: results.length,
    counts: {
      onSpec: 0,
      offSpec: 0,
      tooSimilar: 0
    },
    styleMatch: {
      mean: null
    }
  };

  let styleSum = 0;
  let styleCount = 0;

  for (const r of results) {
    if (r.eval) {
      if (r.eval.onSpec) summary.counts.onSpec += 1;
      else summary.counts.offSpec += 1;
      if (r.eval.tooSimilarToReal) summary.counts.tooSimilar += 1;
      if (typeof r.eval.styleMatchScore === 'number') {
        styleSum += r.eval.styleMatchScore;
        styleCount += 1;
      }
    }
  }

  if (styleCount > 0) {
    summary.styleMatch.mean = styleSum / styleCount;
  }

  fs.mkdirSync(path.dirname(REPORT_FILE), { recursive: true });
  fs.writeFileSync(
    REPORT_FILE,
    JSON.stringify(
      {
        summary,
        results
      },
      null,
      2
    ),
    'utf8'
  );

  console.log('\n‚úÖ Edexcel question eval report written to:', REPORT_FILE);
  console.log('   On-spec questions:', summary.counts.onSpec);
  console.log('   Off-spec questions:', summary.counts.offSpec);
  console.log('   Too-similar questions:', summary.counts.tooSimilar);
  if (summary.styleMatch.mean != null) {
    console.log('   Mean styleMatchScore:', summary.styleMatch.mean.toFixed(3));
  }
}

main().catch((err) => {
  console.error('‚ùå Failed to run Edexcel question eval:', err.message);
  process.exit(1);
});


